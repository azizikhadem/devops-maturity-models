{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1846dc-327a-43c1-98cc-a1ce61cdc28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Install Required Libraries\n",
    "# !pip install pandas faiss-cpu sentence-transformers openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f4adc58-9e6e-4514-b251-e0dac4db8aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your DevOps maturity model question (or type 'exit' to quit):  automation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Chunks:\n",
      " \n",
      "\n",
      "---\n",
      "Answer from OpenAI:\n",
      "\n",
      "As a DevOps maturity model expert, I can say that automation is a critical aspect of DevOps. It refers to the process of using technology to perform tasks with reduced human assistance. In the context of DevOps, automation can be applied to various stages of the software delivery lifecycle, including development, testing, deployment, and operations. \n",
      "\n",
      "In the DevOps maturity model, automation is often seen as a progression. Organizations may start with basic automation of build and deployment processes and gradually move towards more advanced practices like infrastructure as code, automated testing, and automated monitoring and recovery. \n",
      "\n",
      "The ultimate goal is to achieve Continuous Integration/Continuous Delivery (CI/CD), where code changes are automatically built, tested, and deployed to production. This not only speeds up the software delivery process but also reduces the risk of human error and improves the overall quality of the software.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your DevOps maturity model question (or type 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from openai import OpenAI\n",
    "\n",
    "# Step 1: Model synonym mapping (all lowercase)\n",
    "MODEL_SYNONYMS = {\n",
    "    \"bizdevops\": [\"bizdevops\", \"biz\"],\n",
    "    \"bucena\": [\"bucena\", \"bucena maturity model\", \"bucena mm\"],\n",
    "    \"calms\": [\"calms\",\"calm\"],\n",
    "    \"cmmi\": [\"cmmi\", \"capability maturity model integration\"],\n",
    "    \"capgemini\": [\"capgemini\", \"cap gemini\"],\n",
    "    \"dmm4ssc\": [\"devops maturity model for small software companies\",\"dmm4ssc\"],\n",
    "    \"de feijter\": [\"de feijter\", \"defeijter\"],\n",
    "    \"eficode\": [\"eficode\",\"efi code\",\"eficod\"],\n",
    "    \"hp\": [\"hp\", \"hewlett-packard\",\"hewlett packard\"],\n",
    "    \"ibm\": [\"ibm\", \"international business machines\"],\n",
    "    \"mmbdo (maturity model for bizdevops)\": [\n",
    "        \"mmbdo\", \"mmbdo (maturity model for bizdevops)\",\n",
    "        \"mmbdo (maturity model for biz)\", \"mmbdo(maturitymodelforbizdevops)\",\n",
    "        \"mmbdo ( for bizdevops)\"\n",
    "    ],\n",
    "    \"mohamed\": [\"mohamed\",\"mohammed\"],\n",
    "    \"neubrand\": [\"neubrand\",\"neu brand\",\"newbrand\",\"new brand\"],\n",
    "    \"quantitative maturity assessment of devsecops\": [\n",
    "        \"quantitative maturity assessment of devsecops\",\n",
    "        \"quantitativematurityassessmentofdevsecops\",\n",
    "        \"qmaodso\"\n",
    "    ],\n",
    "    \"radstaak\": [\"radstaak\",\"radstak\",\"rad staak\",\"rad stak\"],\n",
    "    \"teixeira\": [\"teixeira\"],\n",
    "    \"xmatters\": [\"xmatters\",\"xmatter\"],\n",
    "    \"rmcosd\": [\"rmcosd\",\"readiness model for cloud outsourcing software development\" ],\n",
    "    \"dcmm\": [\"dcmm\",\"devops capability maturity model\" ],\n",
    "    \"opensamm\" : [\"opensamm\",\"open software assurance maturity model\",\"open samm\",\"opensam\",\"open sam\"]\n",
    "}\n",
    "\n",
    "# Step 2: Load and clean datasets\n",
    "df_models = pd.read_csv(\"devops_maturity_models.csv\")\n",
    "df_components = pd.read_csv(\"mmcmse.csv\")\n",
    "\n",
    "df_models.columns = df_models.columns.str.strip().str.lower()\n",
    "df_components.columns = df_components.columns.str.strip().str.lower()\n",
    "\n",
    "# Step 3: Normalize model name using synonyms\n",
    "def normalize_model_name(name):\n",
    "    name = str(name).lower().strip()\n",
    "    for canonical, aliases in MODEL_SYNONYMS.items():\n",
    "        if name == canonical or name in aliases:\n",
    "            return canonical.title()\n",
    "    return name.title()\n",
    "\n",
    "# Step 4: Extract model names from context\n",
    "def extract_model_name(context):\n",
    "    context = str(context).lower()\n",
    "    for canonical, aliases in MODEL_SYNONYMS.items():\n",
    "        for alias in aliases:\n",
    "            if alias in context:\n",
    "                return canonical.title()\n",
    "    return None\n",
    "\n",
    "df_components[\"model\"] = df_components[\"context\"].apply(extract_model_name)\n",
    "\n",
    "# Step 5: Create semantic chunks\n",
    "def create_chunks(df_models, df_components):\n",
    "    chunks = []\n",
    "\n",
    "    df_models[\"maturity_model_name\"] = df_models[\"maturity_model_name\"].apply(normalize_model_name)\n",
    "    df_components[\"model\"] = df_components[\"model\"].apply(normalize_model_name)\n",
    "\n",
    "    for _, row in df_models.iterrows():\n",
    "        model = row['maturity_model_name']\n",
    "        if pd.isna(model):\n",
    "            continue\n",
    "        text_parts = [f\"Maturity Model: {model}\"]\n",
    "        for col in ['dimension', 'subdimension', 'level', 'metric', 'success_factor', 'evaluation_method']:\n",
    "            val = row.get(col)\n",
    "            if pd.notna(val) and str(val).strip() != \"\":\n",
    "                text_parts.append(f\"{col.capitalize()}: {val}\")\n",
    "        if len(text_parts) > 1:\n",
    "            full_text = \"\\n\".join(text_parts)\n",
    "            chunks.append({\"model\": model, \"text\": full_text, \"source\": \"devops_maturity_models\"})\n",
    "\n",
    "    for _, row in df_components.iterrows():\n",
    "        if pd.notna(row.get(\"context\")) and pd.notna(row.get(\"keyword\")):\n",
    "            model = row.get(\"model\", \"Unknown\")\n",
    "            entry = f\"Maturity Model: {model}\\n{row['type'].capitalize()}: {row['keyword']}\\nContext: {row['context']}\"\n",
    "            chunks.append({\"model\": model, \"text\": entry, \"source\": \"mmcmse\"})\n",
    "\n",
    "    return pd.DataFrame(chunks)\n",
    "\n",
    "# Step 6: Build FAISS index\n",
    "def build_faiss_index(df_chunks, model_name=\"all-MiniLM-L6-v2\"):\n",
    "    embedder = SentenceTransformer(model_name)\n",
    "    embeddings = embedder.encode(df_chunks[\"text\"].tolist(), convert_to_tensor=False)\n",
    "    embeddings = normalize(np.array(embeddings))\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    return index, embeddings, embedder\n",
    "\n",
    "# Step 7: Semantic search\n",
    "def search_query(query, df_chunks, index, embedder, top_k=10):\n",
    "    query_vec = embedder.encode([query], convert_to_tensor=False)\n",
    "    query_vec = normalize(np.array(query_vec))\n",
    "    D, I = index.search(query_vec, top_k)\n",
    "    results = df_chunks.iloc[I[0]]\n",
    "\n",
    "    # ðŸ§¹ Filter out missing/unknown models\n",
    "    results = results[results[\"model\"].notna() & (results[\"model\"].str.lower() != \"none\") & (results[\"model\"].str.strip() != \"\")]\n",
    "    return results\n",
    "\n",
    "# Step 8: RAG context generation\n",
    "def generate_rag_context(query, df_chunks, index, embedder, top_k=30):\n",
    "    # Normalize query for case-insensitive matching\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    # Step 1: Match models from user query using synonyms (case-insensitive)\n",
    "    matched_models = []\n",
    "    for canonical_model, aliases in MODEL_SYNONYMS.items():\n",
    "        for alias in aliases:\n",
    "            if alias.lower() in query_lower:\n",
    "                matched_models.append(canonical_model)\n",
    "                break  # No need to check other aliases for this model\n",
    "\n",
    "    # Step 2: If matched, return only those chunks\n",
    "    if matched_models:\n",
    "        # Normalize model names in df_chunks for comparison\n",
    "        df_chunks[\"model_normalized\"] = df_chunks[\"model\"].str.lower().str.strip()\n",
    "\n",
    "        allowed_models = [model.lower().strip() for model in matched_models]\n",
    "        filtered_chunks = df_chunks[df_chunks[\"model_normalized\"].isin(allowed_models)]\n",
    "\n",
    "        # Remove duplicate rows by text\n",
    "        filtered_chunks = filtered_chunks.drop_duplicates(subset=\"text\")\n",
    "\n",
    "        context = \"\\n---\\n\".join(filtered_chunks[\"text\"].tolist())\n",
    "        return context\n",
    "\n",
    "    # Step 3: If no explicit model match, fall back to semantic search\n",
    "    retrieved = search_query(query, df_chunks, index, embedder, top_k)\n",
    "    context = \"\\n---\\n\".join(retrieved[\"text\"].drop_duplicates().tolist())\n",
    "    return context\n",
    "\n",
    "\n",
    "\n",
    "# Step 9: OpenAI query with context\n",
    "def query_openai_with_context(user_query, retrieved_context, api_key, model=\"gpt-4\"):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    system_prompt = \"You are a DevOps maturity model expert. Answer questions based on the following information.\"\n",
    "    full_prompt = f\"{retrieved_context}\\n\\nUser Question: {user_query}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": full_prompt}\n",
    "        ],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Step 10: Pipeline runner\n",
    "def run_rag_pipeline(user_query, api_key, top_k=10):\n",
    "    df_chunks = create_chunks(df_models, df_components)\n",
    "    index, embeddings, embedder = build_faiss_index(df_chunks)\n",
    "    context = generate_rag_context(user_query, df_chunks, index, embedder, top_k=top_k)\n",
    "    print(\"Retrieved Chunks:\\n\", context)\n",
    "    print(\"\\n---\\nAnswer from OpenAI:\\n\")\n",
    "    answer = query_openai_with_context(user_query, context, api_key)\n",
    "    print(answer)\n",
    "\n",
    "# Step 11: Interactive input loop\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"OpenAI_Key\"\n",
    "    while True:\n",
    "        user_query = input(\"\\nEnter your DevOps maturity model question (or type 'exit' to quit): \")\n",
    "        if user_query.strip().lower() == 'exit':\n",
    "            print(\"Exiting.\")\n",
    "            break\n",
    "        run_rag_pipeline(user_query, api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc3e12b-95c0-43e3-ad9d-ae6a4b0a04b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
